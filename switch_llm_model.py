#!/usr/bin/env python3
"""
Switch LLM Model - Easily change between modern LLM models
CVPilot - Quick utility to switch between GPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro
"""

import os
from pathlib import Path
from rich.console import Console
from rich.prompt import Prompt, Confirm
from src.utils.model_selector import ModelSelector, setup_environment_for_model

console = Console()

def switch_llm_model():
    """Interactive utility to switch between modern LLM models"""

    console.print("[bold blue]ðŸ”„ LLM Model Switcher[/bold blue]")
    console.print("[bold yellow]Switch between modern AI models for better CV generation[/bold yellow]")
    console.print("=" * 60)

    # Initialize model selector
    selector = ModelSelector()

    # Show current configuration
    current_provider = os.getenv("LLM_PROVIDER", "openai")
    current_model = os.getenv("LLM_MODEL", "gpt-4o")

    console.print(f"\n[cyan]ðŸ“Š Current Configuration:[/cyan]")
    console.print(f"   Provider: {current_provider.upper()}")
    console.print(f"   Model: {current_model}")

    # Show available models
    console.print(f"\n[cyan]ðŸ¤– Available Modern Models:[/cyan]")
    selector.list_available_models()

    # Quick recommendations
    console.print(f"\n[cyan]ðŸ’¡ Quick Recommendations:[/cyan]")
    console.print(f"   [green]ðŸŽ¯ Best Quality:[/green] {selector.recommend_model('quality').display_name}")
    console.print(f"   [yellow]âš¡ Best Speed:[/yellow] {selector.recommend_model('speed').display_name}")
    console.print(f"   [blue]ðŸ’° Best Cost:[/blue] {selector.recommend_model('cost').display_name}")

    # Interactive selection
    console.print(f"\n[bold cyan]ðŸŽ® Choose your model:[/bold cyan]")
    console.print("1. Best Quality (GPT-4o)"    console.print("2. Best Speed (Gemini 1.5 Flash)"    console.print("3. Best Cost (Gemini 1.5 Flash)"    console.print("4. Claude 3.5 Sonnet (Balanced)"    console.print("5. Custom Selection"    console.print("6. Keep Current"    console.print()

    choice = Prompt.ask("Select option", choices=["1", "2", "3", "4", "5", "6"], default="1")

    if choice == "6":
        console.print("[green]âœ… Keeping current configuration[/green]")
        return

    # Select model based on choice
    if choice == "1":
        model = selector.recommend_model("quality")
        console.print(f"[green]ðŸŽ¯ Selected: Best Quality ({model.display_name})[/green]")
    elif choice == "2":
        model = selector.recommend_model("speed")
        console.print(f"[green]âš¡ Selected: Best Speed ({model.display_name})[/green]")
    elif choice == "3":
        model = selector.recommend_model("cost")
        console.print(f"[green]ðŸ’° Selected: Best Cost ({model.display_name})[/green]")
    elif choice == "4":
        model = selector.models['claude-3-5-sonnet']
        console.print(f"[green]ðŸ§  Selected: Claude 3.5 Sonnet[/green]")
    else:
        # Custom selection
        model = selector.interactive_selection()
        if not model:
            return

    # Confirm selection
    console.print(f"\n[bold cyan]ðŸ”§ Configuration Preview:[/bold cyan]")
    console.print(f"   LLM_PROVIDER={model.provider}")
    console.print(f"   LLM_MODEL={model.model}")
    console.print(f"   Model: {model.display_name}")
    console.print(f"   Description: {model.description}")

    # Update environment variables
    if Confirm.ask(f"\nðŸ¤” Apply this configuration now?"):
        # Set environment variables
        os.environ["LLM_PROVIDER"] = model.provider
        os.environ["LLM_MODEL"] = model.model

        console.print("[green]âœ… Environment variables updated![/green]")
        console.print("[cyan]ðŸ’¡ For permanent changes, add to your .env file:[/cyan]")
        setup_environment_for_model(model)

        console.print("
[bold green]ðŸŽ‰ Ready to test![/bold green]")
        console.print("Run: [cyan]python -m src.main --job-id 159[/cyan]")

        # Offer to test immediately
        if Confirm.ask("ðŸš€ Test with job ID 159 now?"):
            console.print("[blue]Running test...[/blue]")
            os.system("python -m src.main --job-id 159")

    else:
        console.print("[yellow]â„¹ï¸ Configuration not applied[/yellow]")

def show_model_comparison():
    """Show detailed comparison between modern models"""

    console.print("[bold blue]ðŸ“Š Modern LLM Model Comparison[/bold blue]")
    console.print("=" * 50)

    models = {
        'GPT-4o': {
            'provider': 'OpenAI',
            'quality': 'â­â­â­â­â­ (95%)',
            'speed': 'â­â­â­â­ (80%)',
            'cost': 'â­â­â­â­ (70%)',
            'best_for': 'Maximum quality, complex analysis'
        },
        'Claude 3.5 Sonnet': {
            'provider': 'Anthropic',
            'quality': 'â­â­â­â­â­ (92%)',
            'speed': 'â­â­â­â­â­ (85%)',
            'cost': 'â­â­â­â­â­ (80%)',
            'best_for': 'Creative writing, detailed analysis'
        },
        'Gemini 1.5 Pro': {
            'provider': 'Google',
            'quality': 'â­â­â­â­ (88%)',
            'speed': 'â­â­â­â­â­ (90%)',
            'cost': 'â­â­â­â­â­ (90%)',
            'best_for': 'Fast processing, good balance'
        },
        'Gemini 1.5 Flash': {
            'provider': 'Google',
            'quality': 'â­â­â­â­ (82%)',
            'speed': 'â­â­â­â­â­ (95%)',
            'cost': 'â­â­â­â­â­ (95%)',
            'best_for': 'High volume, cost-effective'
        }
    }

    from rich.table import Table

    table = Table(title="Modern LLM Comparison")
    table.add_column("Model", style="cyan", width=20)
    table.add_column("Provider", style="magenta", width=12)
    table.add_column("Quality", style="green", width=15)
    table.add_column("Speed", style="yellow", width=12)
    table.add_column("Cost", style="blue", width=12)
    table.add_column("Best For", style="white", width=25)

    for model_name, specs in models.items():
        table.add_row(
            model_name,
            specs['provider'],
            specs['quality'],
            specs['speed'],
            specs['cost'],
            specs['best_for']
        )

    console.print(table)

    console.print("\n[bold cyan]ðŸŽ¯ Recommendations:[/bold cyan]")
    console.print("   [green]ðŸŽ¯ Maximum Quality â†’ GPT-4o or Claude 3.5 Sonnet[/green]")
    console.print("   [yellow]âš¡ Maximum Speed â†’ Gemini 1.5 Flash[/yellow]")
    console.print("   [blue]ðŸ’° Cost Effective â†’ Gemini models[/blue]")
    console.print("   [purple]ðŸ§  Balanced â†’ Claude 3.5 Sonnet[/purple]")

if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "--compare":
        show_model_comparison()
    else:
        switch_llm_model()
